# Processing of strong-motion accelerograms: needs, options and consequences

David M. Boore<sup>a</sup>, Julian J. Bommer<sup>b,*</sup>

$^{a}$ US Geological Survey, 345 Middlefield Road, Menlo Park, CA 94025, USA  
 $^{b}$ Civil and Environmental Engineering, Imperial College London, London SW7 2AZ, UK

Accepted 25 October 2004

# Abstract

Recordings from strong-motion accelerographs are of fundamental importance in earthquake engineering, forming the basis for all characterizations of ground shaking employed for seismic design. The recordings, particularly those from analog instruments, invariably contain noise that can mask and distort the ground-motion signal at both high and low frequencies. For any application of recorded accelerograms in engineering seismology or earthquake engineering, it is important to identify the presence of this noise in the digitized time-history and its influence on the parameters that are to be derived from the records. If the parameters of interest are affected by noise then appropriate processing needs to be applied to the records, although it must be accepted from the outset that it is generally not possible to recover the actual ground motion over a wide range of frequencies. There are many schemes available for processing strong-motion data and it is important to be aware of the merits and pitfalls associated with each option. Equally important is to appreciate the effects of the procedures on the records in order to avoid errors in the interpretation and use of the results. Options for processing strong-motion accelerograms are presented, discussed and evaluated from the perspective of engineering application.

© 2004 Elsevier Ltd. All rights reserved.

Keywords: Strong-motion accelerograms; Signal-to-noise ratios; Instrument corrections; Baseline adjustments; Filters

# 1. Introduction

Seismic design is primarily concerned with the balance between the potential of ground shaking to cause damage (demand) and the ability of structures to resist damage (capacity). The seismic capacity of engineered structures can be assessed from experimentation, analytical modeling and field observations following earthquakes, and indeed from the interaction of these three channels of investigation. The characterization of seismic demand, on the other hand, has been developed primarily from recordings obtained from strong-motion accelerographs. The global databank of strong-motion accelerographs that has been accumulated since the first records were obtained in Long Beach, CA, in

1933, has been of primordial importance to the development of earthquake engineering.

Although strong-motion accelerograms have provided seismologists and engineers with valuable insight into the nature of earthquake ground shaking close to the earthquake source—where damage can be expected—the information that can be retrieved from the recordings is limited: it can never be claimed that a complete and accurate description of the ground shaking can be obtained from accelerograms. For engineering uses of strong-motion data it is important to be able to estimate the level of noise present in each accelerometer and the degree to which this may affect different parameters that are derived from the records. The main parameters of interest for engineering application are the ordinates of response spectra, both of acceleration and displacement. The peak ground acceleration (PGA), although of limited significance from both geophysical and engineering perspectives, is also a widely used parameter in engineering. The peaks of velocity (PGV) and displacement (PGD), measured from the time-histories

obtained by integration of the acceleration, are also important parameters. The focus of this paper is on the effects of noise in accelerograms, and the effects of 'correction' procedures, on the peak ground-motion amplitudes and on the ordinates of acceleration and displacement response spectra.

The objective of the paper is to provide engineering seismologists and earthquake engineers who are not specialized in strong motion with an overview of reasons for which record processing is performed, the options available for carrying out this processing, and the consequences of applying each of the available approaches. The paper also aims to highlight the fact that there is no panacea that can be prescribed for record processing and that a degree of subjectivity is involved. Generally it is not possible to identify the 'best' processing for an individual record: assumptions always need to be made and the optimal procedure for a given record will depend on the application. The limitations of the data and the processing routines need to be appreciated by the end users.

Following this introduction, the paper begins with an overview of the sources and nature of noise in accelerograms, making the important distinction between analog and digital recordings, whilst highlighting the fact that digital recordings are by no means entirely free of noise. The distinction is also made between the standard types of noise, for which the routine processing techniques discussed in the main body of the paper are appropriate, and non-standard errors that should be removed prior to the application of any general processing. Section 3 of the paper deals with high-frequency noise and distortion due to the dynamic characteristics of the instrument, discussing procedures that can be applied to compensate for these effects. Throughout the paper, the procedures are qualified by the adjective 'adjustment' rather than 'correction', since the boundary conditions are nearly always unknown and hence users should be aware that the true ground motion, across the full range of periods that may be of engineering interest, cannot be unambiguously determined. The fourth section of the paper discusses baseline adjustments, both for the effects of reference baseline shifts (introduced at the recording or digitizing stages) and as a technique to remove long-period noise. This section closes with a discussion of the special group of baseline fitting procedures that do not impose the condition of zero displacement at the end of the motion.

Section 5 of the paper deals with the use of filters as a tool for the reduction of long-period noise in the accelerograms, probably the most important issue for engineering applications of strong-motion data as well as the area in which there is the greatest confusion. This section begins with the issue of choosing a filtering technique, the key issues being whether the filter is causal or acausal. This is followed by a discussion of the compatibility of the results produced, which is related to how the chosen filter is applied and to the how the processed records are handled. Options for selecting the filter parameters—and in particular the all

important long-period cut-off—are then presented, followed by a discussion of the implications of these parameters for the usable period range of response spectral ordinates. The question of whether the same filter parameters should be applied to the three components of triaxial accelerograms is then briefly addressed. The section closes with a discussion of the combined use of filters and baseline adjustments.

# 2. Noise characteristics of strong-motion data

The purpose of recording strong earthquake shaking is to obtain detailed information regarding the ground motion of engineering interest, which can be referred to as the signal. For a variety of reasons, explained below, digitized accelerograms also contain extraneous 'motions' that are referred to as noise. From the outset it is important for users of strong-motion data to appreciate that digitized accelerograms are never pure and complete reproductions of the seismic signal. The purpose of processing accelerograms, which is the topic of this paper, is to optimize the balance between acceptable signal-to-noise ratios and the information required for a particular application, both of which depend on period or frequency.

# 2.1. Analog and digital accelerographs

The first accelerographs were developed in the US in 1932, almost four decades after the first seismographs were installed, the delay being due to the difficulty in producing instruments sufficiently sensitive to produce detailed recordings of the ground motion whilst being robust enough to remain operational when subjected to strong shaking. The first strong-motion accelerograms were obtained in the Long Beach (California) earthquake of March 1933. Over the 70 years since the Long Beach earthquake, thousands of accelerographs have been installed around the world and the global databank of strong-motion records—which already numbers tens of thousands—continues to grow at an ever increasing rate.

The first accelerographs were optical-mechanical devices, generally referred to as analog recorders. These instruments produced traces of the ground acceleration against time on film or paper; the most widely used and best known analog accelerometer was the Kinematics SMA-1. Analog accelerographs present three important disadvantages, the first being that in order not to waste vast quantities of the recording medium, they operate on standby, triggered by a specified threshold of acceleration, which means that the first motions are often not recorded. The second disadvantage is related to their dynamic characteristics: for the displacement response of a simple pendulum to be proportional to the acceleration of its base (which is the objective of the transducer in an accelerometer), the natural frequency of vibration of the pendulum must be much greater than the frequency of the motion being recorded.

A pendulum of very high frequency would need to be extremely stiff, hence the displacement of its mass would be very small and to obtain a clearly decipherable record would require a large separation of the mass and the recording film, resulting in impractically large instruments. As a result, the natural frequency of transducers in analog instruments was generally limited to about  $25\mathrm{Hz}$ . The third (and most important) disadvantage of analog instruments is the simple fact that in order to be able to use the recording in any engineering analysis, it is necessary to digitize the traces, a process that is time-consuming and laborious, as well as being one of the primary sources of noise.

Digital accelerographs came into operation almost 50 years after the first analog strong-motion recorders. Digital instruments provide a solution to the three disadvantages associated with the earlier accelerographs: since they record on re-usable media, they operate continuously and by use of pre-event memory are able to retain the first wave arrivals, regardless of how weak these are; their frequency range is much wider, the transducers having natural frequencies of  $50 - 100\mathrm{Hz}$  or even higher; and the analog-to-digital conversion is performed within the instrument, thus obviating the need to digitize the records. In addition, direct digital recording also provides more resolution than digitizing of an analog recording.

Digital accelerographs come much closer to producing records of the actual seismic signal than their analog counterparts, although, as shown later, some degree of record processing is still required. The convenience that digital accelerographs present tempts some to disregard the global databank of strong-motion recordings obtained from analog instruments, but this would be to lose a wealth of information. The first digital recordings of earthquake shaking were obtained in the late 1970s but even up to the middle of the last decade, most important earthquake

recordings were obtained from analog instruments: for example, more than half of the accelerograms from the 1994 Northridge (California) earthquake were obtained on analog recorders. Only at the end of the 1990s did the first large earthquakes, such as the 1999 events at Hector Mine (USA), Kocaeli (Turkey) and Chi-Chi (Taiwan), occur that were recorded predominantly by digital accelerographs. However, analog instruments still continue to contribute important records: many of the near-source records from the Parkfield, California, earthquake of 28 September 2004 were obtained on analog accelerographs. Several decades will pass before the databank of analog accelerograms becomes redundant, and until then it is important to understand why these records require processing, the options for performing the required processing, and the consequences in terms of reliability and limits of the data.

# 2.2. Analog accelerograms

Provided that accurately determined values of the acceleration and time scales are used in creating the digitized version of an analog accelerometer, the problems of noise in the record are generally not apparent from inspection of the acceleration time-history, except where non-standard errors occur (Section 2.4). The most important effects of noise in the record only become apparent when the acceleration trace is integrated to obtain the velocity and displacement time-histories (Fig. 1).

Some types of noise, particularly step changes in the baseline, can also be identified from the 'jerk', which is the first derivative of the acceleration trace. The velocity and displacements obtained from integration of the accelerogram will generally appear unphysical, as is clearly the case in the left-hand plots of Fig. 1: the ground motion appears as a single asymmetrical elastic displacement pulse of more

![](images/dd1924a7559204d6ed02755b58ee0c6576753330a1e03b8b5f873962e10d435c.jpg)  
Fig. 1. Acceleration, velocity and displacement for an analog (left) and a digital (right) record. The analog record has been shifted to the right for clarity; it starts at a time of  $0.0\mathrm{~s}$ . Prior to integration, the mean of acceleration was subtracted from the analog recording and the mean of the pre-event memory from the digital recording.

![](images/f472325c50e56ff2b9274501b67cbff3ddf3b9a4276a784b849879970e854cdf.jpg)

than  $2\mathrm{m}$  amplitude. The unphysical nature of the velocities and displacements obtained from integration are in small part due to the unknown boundary conditions: the initial velocity and displacement are both assumed to be zero but because of the signal lost prior to triggering this may not be the case. Of much greater importance, however, are the unknown baseline and the long-period noise coming from a variety of sources but predominantly from the imperfection of tracking in digitizers [1-3]. Long-period noise can also be introduced by lateral movements of the film during recording and warping of the analog record prior to digitization.

In subsequent sections of this paper, an overview of procedures for dealing with the noise in the digitized records is presented. From the outset, however, it is important to be clear that it is not possible to identify, separate and remove the noise in order to recover the unadulterated seismic signal. The best that can be achieved in general is to identify those portions of the frequency content of the record where the signal-to-noise ratio is unacceptably low and to thus identify that portion of the record, in the frequency domain, that can be used with some confidence. The processing generally involves the removal of most of the record at frequencies where the Fourier amplitude spectrum shows a low signal-to-noise ratio, and the critical issue for end users is to appreciate the limitations of what remains after the contaminated frequencies have been cut out of the record. In light of these considerations, we do not believe that it is appropriate to refer to most of the processing procedures described herein as 'corrections', since the term implies that the real motion is known and furthermore that it can be recovered by applying the procedures.

In order to estimate the signal-to-noise ratio, a model of the noise in the digitized record is required. Most analog accelerographs, such as the SMA-1, produce two fixed traces on the film together with the three traces of motion (two horizontal, one vertical) and the time marks. If these fixed traces are digitized together with the motion, then any 'signal' they contain can be interpreted as being composed entirely of noise since the traces are produced by infinitely stiff transducers that experience no vibration during the operation of the instrument. Unfortunately, the fixed traces are very often not digitized or else the digitized fixed traces are not kept and distributed with the motion data, hence it is rare that a model of the noise can be obtained from this information. A number of studies have examined the typical noise resulting from different digitization processes [4-6]; these provide a useful resource but it should be borne in mind that they generally correspond to a particular combination of accelerometer and digitizer, neither of which will necessarily correspond to the data at hand.

# 2.3. Digital accelerograms

Digital accelerographs, as stated earlier, present many advantages with respect to analog instruments. In particular,

problems encountered in the high-frequency range with digitized analog records (discussed in Section 3), are effectively eliminated as a result of the improved dynamic range, the higher sampling rate and the obviation of the digitization process. However, the need to apply processing to the records is not entirely eliminated, as can be appreciated from the right-hand plots in Fig. 1: the true baseline of the record is still unknown and this manifests in the velocity and displacement time-histories obtained by double integration. As discussed in Section 2.4, the nature of baseline errors in digital recordings can be very distinct from those routinely encountered in digitized analog recordings. One distinct advantage of digital recordings is that the pre- and post-event memory portions of the recordings provide a direct model for the noise in the record. However, it is often found that the most important component of the noise is actually associated with the signal itself, hence the pre-event memory provides an incomplete model for the noise in the record since it does not capture the 'signal-generated noise'.

# 2.4.Standard vs non-standard noise

The noise encountered in digitized records from analog instruments is understood to arise from the characteristics of the instrument and the digitizer, and apart from the dependence of the noise on frequency it generally manifests throughout the digitized record. In many records, however, errors are sometimes found that do not correspond to the usual sources of noise [7]. Although many of these non-standard errors will be removed—or concealed—by the application of standard processing procedures, it is preferable to identify them and, to the extent possible, remove them prior to undertaking routine processing.

An example of non-standard error is shown in Fig. 2: spurious 'spikes' in the digitized record can be identified at about 10.8, 16 and  $26\mathrm{s}$ . In this particular case, the spurious nature of these spikes was confirmed by comparison with a reproduction of the original analog record; the origin of the spikes has not been ascertained, although a possible cause in this instance was the misplacement of the decimal point in transcribing the digitized values (J. Douglas, personal communication, 2004).

Once the spikes have been identified as erroneous, they should be removed from the digitized record; one way to achieve this is replace the acceleration ordinate of the spike with the mean of the accelerations of the data points either side. The spectra in Fig. 3 were obtained with the record shown in Fig. 2 before and after the spikes were removed; the spikes clearly constituted a serious noise contamination at short periods but it is also noted that their elimination appears to have led to slight modifications in the spectrum at long periods (spikes are broadband and have energy content at long as well as short periods). Of course, if the misplacement of decimal points is identified as the cause of the errors, then an exact correction could be made.

![](images/be9683fea7859e99a8b798e416cb1213f05ca2bc747f2620087306eb5a7bdf22.jpg)  
Fig. 2. Horizontal component of the Bajestan recordings of the 1978 Tabas earthquake in Iran; spurious spikes are obvious in the acceleration record at 10.8 and  $16\mathrm{s}$ . The derivative of the acceleration trace (to produce the quantity called 'jerk') will convert a spike into a double sided pulse, making it easier to identify spikes. By doing this (bottom panel), spikes at 12.3, 26 and  $33.2\mathrm{s}$  are also identified.

A problem encountered with some digitized analogue records is shifts in the baseline, which are presumed to be the result of the record being digitized in sections and these then not being correctly spliced together (Fig. 4). A very similar problem is frequently encountered in accelerograms from digital instruments, although the cause in those cases is often related to the actual instrument operation [8-10] or even the process of analog-to-digital conversion [11].

![](images/dc49780628ad493bd5deb1fd4513dd83e9802fc076f23acddd32cfdca7a87d12.jpg)  
Fig. 3. Acceleration response spectra (5% damped) from the accelerometer in Fig. 2 before and after removal of the spikes.

![](images/95861e14d04b19717f863cff8d920acdb1f0fa6b58cdebf78df0f7f2bfa57d77.jpg)  
Fig. 4. NS component of the 21 May 1979 Italian earthquake (12:36:41 UTC) recorded at Nocera Umbra, showing shifts in the baseline at 5.6 and  $8.3\mathrm{s}$ .

Regardless of the cause of the baseline shifts, the procedure to compensate for their effect is essentially the same for both analog and digital recordings; these are described in Section 4.1.

# 3. High-frequency noise and instruments effects

As noted earlier, the transducer frequency in analog instruments is limited to about  $25\mathrm{Hz}$ , and this results in distortions of amplitudes and phases of the components of ground motion at frequencies close to or greater than that of the transducer [1,2,12]. The digitization process itself can also introduce high-frequency noise as a result of the random error in the identification of the exact mid-point of the film trace ([13], Fig. 5). The degree to which either or both of these effects matter depends both on the frequency content of the ground motion and on the engineering application.

The left-hand plot in Fig. 6 shows an example of the Fourier spectra of high-frequency ground motion obtained at a very hard rock site in Canada at a distance of  $4\mathrm{km}$  from the source of a small magnitude earthquake. Softer sites, even those classified as 'rock' such as class B in the 2003 NEHRP guidelines [14], will tend to filter out such high-frequency motion. Very high-frequency motions will also tend to attenuate rapidly with distance and hence will not be observed at stations even a few tens of kilometers from the fault rupture. The plot in Fig. 6 also shows the typical transducer response for the instrument (SMA-1) on which the record was obtained, and the effect of applying a correction for the instrument characteristics, which is to increase slightly the amplitudes at frequencies greater than  $30\mathrm{Hz}$ . The nature of such motions, at periods of less than  $0.03\mathrm{s}$ , will only be relevant to particular engineering

![](images/c587746f69162953bd36e5358603398a8fc63946dcfd6e250e23ac2a273984a0.jpg)  
Fig. 5. Fourier acceleration spectrum of an analog recording at a site underlain by thick sediments. Natural processes along the propagation path have removed energy at frequencies much below those affected by the instrument response (see dashed line; the instrument response has been shifted vertically so as not to be obscured by the data), leading to the decreasing spectral amplitudes with increasing frequency up to about  $26\mathrm{Hz}$  (coincidentally the same as the instrument frequency), at which point noise produces an increase in spectral amplitudes. Instrument correction only exacerbates the contamination of the signal by high frequency noise.

problems, such as the response of plant machinery and non-structural components.

The right-hand plots in Fig. 6 show the Fourier spectra of more typical ground motions obtained at soil sites during a moderate magnitude earthquake in California. These records were obtained on digital instruments and are lacking in very high frequency motion mainly because of the attenuating effect of the surface geology at these sites compared to the very hard site in Canada. The plot also shows the transducer response for these digital instruments, which is almost flat to beyond  $40\mathrm{Hz}$ .

# 3.1. Corrections for transducer characteristics

Early approaches to instrument corrections were based on finite difference schemes using second-order centered differences as an approximation to the derivatives, but it

has been found that these are only effective if the record has been digitized at a high sampling rate [15,16]. Second-order difference techniques are effective for frequencies up to about one-eighth of the sampling frequency. Techniques more widely used in current practice, such as that employed for the corrections shown in Fig. 5 and the left-hand plot of Fig. 6, generally perform the correction by using either higher-order approximations to the derivatives or using frequency-domain corrections [15,17]. The key issue, however, is less about which particular procedure to apply but rather whether an instrument correction should be applied at all. For digital recordings, instrument corrections should not be necessary. For analog recordings, if the engineering application is concerned with motions at frequencies above  $20\mathrm{Hz}$  and the site characteristics are sufficiently stiff for appreciable amplitudes at such frequencies to be expected, a correction should be considered. However, it should be borne in mind that the instrument corrections essentially amplify the high-frequency motions; if the digitization process has introduced high-frequency noise into the record, then the instrument correction will amplify this noise. Unless there are compelling reasons for applying a correction for the instrument characteristics, we recommend that no attempt should be made to do so. The one exception to this may be the very earliest recordings obtained in the US with accelerographs that had natural frequencies of the order of  $10\mathrm{Hz}$ .

# 3.2. Application of high-cut filters

If it is judged that there is significant high-frequency noise in the record, or if for some other reason it is desirable to reduce or remove high frequencies introduced by interaction effects at the recording station, this can be easily achieved by the application of filters. Filters can be applied in the frequency domain or the time domain but their function is best understood in

![](images/e8e4480672935f8daa03e138177ece5dcee38090dc32cfc43be9a8c83bdd16e2.jpg)  
Fig. 6. Fourier acceleration spectra of earthquakes recorded in eastern and western North America (left and right graphs, respectively). The eastern North America recording has much higher frequency content than that from western North America, even without instrument correction. The record from Miramichi was recorded on an analog instrument, whereas those from the Big Bear City earthquake were recorded on digital instruments (the response curves of the instruments are shown by the dashed lines and have been shifted vertically so as not to be obscured by the data).

the frequency domain. The terminology used to describe filters can be confusing, especially for engineers more accustomed to thinking in terms of periods than frequencies. A filter that removes high frequencies (short periods) is usually referred to as a low-pass filter because motion at lower frequencies gets through and higher frequencies are, in effect, blocked by the filter. For such a filter we prefer the term high-cut, which refers directly to the frequencies being removed. The mechanics of filters are discussed further in Section 5.1 in the context of low-cut filtering.

Two considerations are important when applying a high-cut filter. The first is that the application of the filter will act in a contrary manner to any instrument correction and at least in some frequency ranges the two will counteract each other. The second consideration is that an upper frequency limit on the usable range of high frequencies in the motion is imposed by the sampling rate: the Nyquist frequency, which is the highest frequency at which characteristics of the motion can be correctly determined, is equal to  $(1 / 2\Delta t)$  where  $\Delta t$  is the sampling interval. A high-cut filter applied at frequencies greater than the Nyquist will have no effect on the record.

# 4. Reference baseline adjustments

A major problem encountered with both analog and digital accelerograms are distortions and shifts of the reference baseline, which result in unphysical velocities and displacements. One approach to compensating for these problems is to use baseline adjustments, whereby one or more baselines, which may be straight lines or low-order polynomials, are subtracted from the acceleration trace. Section 4.1 describes the use of baselines to correct for the baseline shifts described in Section 2.4. This is followed by a brief discussion of baseline adjustments as a technique for removing long-period noise. The third section discusses the use of baseline fitting techniques to recover permanent ground displacements from accelerograms.

# 4.1. Multi-segment baselines

Fig. 7 illustrates the application of a piece-wise sequential fitting of baselines to the velocity trace from a digital recording in which there are clearly identifiable offsets in the baseline. A similar procedure could be applied

![](images/a17c1844633581435fc56142287c440ae0975602aca4611a028ba49a6256fe2b.jpg)  
Fig. 7. Sequential baseline adjustments applied to the velocity time-history obtained from integration of a digital accelerometer with shifts in the baseline. Note the change in the ordinate scales of the plots.

directly to the acceleration time-history to correct for the type of baseline shifts shown in Fig. 4.

The procedure applied in Fig. 7 is to identify (by blowing up the image) sections of the velocity that appear to have a straight baseline, and then fitting a straight line to this interval. This line in effect is then subtracted from the velocity trace, but in practice it is necessary to apply the adjustment to the accelerations. The adjustment to the acceleration is a simple shift equal to the gradient (i.e. the derivative) of the baseline on the velocity; this shift is applied at a time  $t_{\mathrm{v0}}$ , which is the time at which the line fit to the velocity crosses the zero axis. The adjusted velocity trace is then inspected to identify the next straight line segment, which is fit in the same way. In the particular case illustrated in Fig. 7 a total of four line segments were required to remove the most severe distortions of the baseline visible in uppermost plot, although the baseline instabilities are not entirely removed, as evident in the residual long-period trends.

# 4.2. Baselines to remove long-period noise

The distortion of the baseline encountered in digitized analog accelerograms is generally interpreted as being the result of long-period noise combined with the signal. Baselines can be used as a tool to remove at least part of this noise—and probably some of the signal with it—as a means of recovering more physically plausible velocities and displacements. There are many procedures that can be applied to fit the baselines, including polynomials of different orders. A point that is worth making clearly is

that, in effect, baseline adjustments are low-cut filters of unknown frequency characteristics.

Fig. 8 illustrates two approaches to fitting baselines to the velocity trace, and the changes that they impose on the acceleration trace. One scheme is a simple quadratic fit to the velocity, which is a simplification of the more complex scheme proposed by Graizer [19] in which a series of progressively higher-order polynomials are fit to the velocity trace. The other approach is the more complex scheme proposed by Iwan et al. [8]. The method was motivated by studies of a specific instrument for which the baseline shifted during strong shaking due to hysteresis; the accumulation of these baseline shifts led to a velocity trace with a linear trend after cessation of the strong shaking. The correction procedure approximates the complex set of baseline shifts with two shifts, one between times of  $t_1$  and  $t_2$ , and one after time  $t_2$ . The adjustment scheme can be applied to any record, with the advantage that the velocity will oscillate around zero (a physical constraint), but the scheme requires selection of the times  $t_1$  and  $t_2$ . Without a physical reason for choosing these times (for example, based on a knowledge of a specific instrument), the choices of  $t_1$  and  $t_2$  become subjective, and as illustrated in Fig. 9, the long-period response spectrum ordinates are sensitive to the choice of  $t_2$  ( $t_1$  was not varied in this illustration; it is important to note that for this particular accelerometer the differences in the response spectrum are not significant until beyond 10 s oscillator period).

A commonly used simplification of the generalized Iwan et al. method is to assume that  $t_1 = t_2$ , with the time given by the zero intercept of a line fit to the later part of the velocity trace; this corresponds to the assumption that there was only

![](images/2d6aefe8aa956926bf3c213e4ce8cc6ff1e17c39e08686be2896129098f9930d.jpg)  
Fig. 8. Left: Shaded line: velocity from integration of the east-west component of acceleration recorded at TCU129,  $1.9\mathrm{km}$  from the surface trace of the fault, from the 1999 Chi-Chi earthquake, after removal of the pre-event mean from the whole record. A least-squares line is fit to the velocity from 65 s to the end of the record. Various baseline corrections using the Iwan et al. (1985) scheme are obtained by connecting the assumed time of zero velocity  $t_1$  to the fitted velocity line at time  $t_2$ . Two values of  $t_2$  are shown: 30, and 70 s. The dashed line is the quadratic fit to the velocities, with the constraint that it is 0.0 at  $t = 20$  s. The acceleration time series are obtained from a force-balance transducer with natural frequency exceeding  $50\mathrm{Hz}$ , digitized using  $16.7$  counts/cm/s² (16,384 counts/g). Right: The derivatives of the lines fit to the velocity are the baseline corrections applied to the acceleration trace (from [18]).

![](images/235fdef5fd5f71268970101d2fb5dde3e303320aef1b09380911eacafcad8f72.jpg)

![](images/9c86e8ecdf0b6281922e6193e25e2f4f5772f1c79507cb7d04d835ffb033bcb8.jpg)  
Fig. 9. Response spectra of the east-west component of acceleration recorded at TCU129 from the 1999 Chi-Chi, Taiwan, earthquake, modified using a variety of baseline corrections (from [20]).

one baseline offset and that it occurred at a single time (for many records this seems to be a reasonable assumption). We call this simplification the  $\nu O$  correction [20].

Another variation of the baseline-fitting technique has recently been presented by Zhu [21]. In this study, a polynomial baseline is fitted that has the same coefficients before and after the record, plus a signal that is 0 for  $t < t_1$  and  $D$  for  $t > t_2$ , where  $D$  is the permanent displacement. As noted earlier in Section 2.3, it is often found that there are little or no long-period problems or drifts for the pre-event of digital recordings and the drifts appear to be clearly related to the earthquake shaking. Since the method of Zhu [21] assumes a model for the observed displacement that assumes that the noise is independent of the signal, it might not yield good results for those cases where there is signal-generated noise.

# 4.3. Residual displacements

One of the possible advantages of baseline fitting techniques just discussed is that the displacement trace can obtain a constant level at the end of the motion and can have the appearance of the residual displacement expected in the vicinity of faults (Fig. 10). This character of the displacement record cannot be achieved using low-cut filters.

At the end of the ground shaking caused by an earthquake, the ground velocity must return to zero, and this is indeed a criterion by which to judge the efficacy of the record processing. The final displacement, however, need not be zero since the ground can undergo permanent deformation either through the plastic response of near-surface materials or through the elastic deformation

![](images/b97e95136cc2609e2653c94bb14ca84fe4af2a490d2044160f3ee0e6ee653e1a.jpg)  
Fig. 10. Displacements obtained by double integration of the east-west component of acceleration recorded at TCU129 from the 1999 Chi-Chi, Taiwan, earthquake and modified using a variety of baseline corrections. The GPS level was obtained at a station  $2.3\mathrm{km}$  from TCU129, above the footwall of the fault (as is TCU129) (from [18]).

of the Earth due to co-seismic slip on the fault. Close to the fault rupture of large magnitude earthquakes ( $\sim M_{\mathrm{w}} 6.5$  and above) this residual displacement can be on the order of tens or hundreds of centimeters. This can become an important design consideration for engineered structures that cross the trace of active faults, cases in point being the Trans Alaskan Pipeline System [22] and the Bolu viaduct in Turkey [23,24], the former being traversed by the fault rupture of the November 2002 Denali earthquake, the latter by the rupture associated with the November 1999 Düzce earthquake.

The problem presented by trying to recover the residual placement through baseline fitting is that the resulting offset can be highly sensitive to the choice of parameters (Fig. 10) and furthermore there are few data with independently-measured offsets exactly at the location of strong-motion instruments. The lack of independently-measured offsets is beginning to be overcome with the installation of continuous GPS stations sampling at sufficiently high rates collocated with accelerographs. A good example of this is on the island of Hokkaido in Japan, where 1 sps continuously recording GPS instruments are co-located at a number of strong-motion sites. These instruments recorded the  $M_{\mathrm{w}}$  8.3 2003 Tokachi-Oki earthquake. The displacements from the GPS instruments agree well with those derived from accelerometers for the first half-cycle of the S-wave arrival (after which the GPS instruments failed to record the motion) [25]. Another very valuable set of co-located recordings from a strong-motion accelerometer (station PKD) and a continuous GPS recording at 1 sps was obtained during the  $M_{\mathrm{w}}$  6.5 San Simeon, California, earthquake of December 2003 [26] and the september 2004 parkfield earthquake.

![](images/f77a3eac7c9b00af73305bad5cbcb3e0e64d6f1b0c855a61b1320fc6283dee7f.jpg)  
Fig. 11. Acceleration, velocity and displacement from the analog and digital recordings shown in Fig. 1. As before, the only processing for the gray traces was to remove the overall mean for the analog record and the pre-event mean for the digital record. The black traces show the velocities and displacements derived from acceleration time series filtered as indicated. The displacement axis labels for the unfiltered motions (gray) are given on the right side of the graphs.

![](images/9f7bb8e3c2c1a834ccd6879fe4bffd634a6b2c26897de121f38d8a24de636d13.jpg)

Some researchers have concluded that it is actually impossible to recover with certainty the permanent offset of the ground from records of the translational movement alone, and that the true displacements can only be determined if the rotational components of the motion are also known [27,28].

# 5. Filters to reduce low-frequency noise

The most widely used—and also the most effective and least subjective—tool for reducing the long-period noise in accelerograms is the low-cut filter [29]. Fig. 11 shows the accelerograms first shown in Fig. 1 after the application of filters to the acceleration time-history, and the improvement in the appearance of velocity and displacement time-histories is obvious; it should also be noted that there is little discernable difference between the filtered and unfiltered accelerations.

Although the benefits of applying filters are clear, it is important to be aware of the sensitivity of the results obtained to the actual parameters selected for the filter (Fig. 12). The selection of these parameters is therefore a critical issue, which is addressed in Section 5.3. This is preceded by two sections dealing with other issues: a brief overview of the mechanics of filtering and in particular the choice between causal and acausal filters, and the issue of compatibility amongst the processed ground motions. The section dealing with the selection of filter parameters is followed by a discussion of the consequences of the filter parameters on the usable range of spectral ordinates with reference to earthquake engineering applications. The final issue addressed is the application of filters to multiple

channel recordings of ground acceleration and recordings of structural response.

# 5.1. Choice of filtering technique

A filter is a function that in the frequency domain has a value close to 1 in the range of frequencies that the analyst wishes to retain and close to zero in the range of frequencies that the analyst wishes to eliminate. The filter can be applied

![](images/ccfdd52aa069370a838958df05098213ee4c6425f334a2792d5f06a1a7e272cc.jpg)  
Fig. 12. Displacement time-histories for a series of filters with different parameters.

![](images/51f8c06fb9c962960d6f1c3de3b7861d9279b46a74e714de71ad3dbe5a7ad5ef.jpg)  
Fig. 13. Illustration of a low-cut Butterworth filter as a function of frequency and period. The filter frequency is  $0.05\mathrm{Hz}$ , which means that periods above  $20\mathrm{s}$  are at least partially removed. The different curves are for different orders of filter: the higher the order, the more abrupt the cut-off. For the lower order filters, information will be removed from periods as low as  $10\mathrm{s}$ .

in the time domain, by convolution of its transform with the time history, or in the frequency domain by multiplying the filter function with the Fourier amplitude spectrum (FAS) of the time history, and then obtaining the filtered time history through the inverse Fourier transform. The choice between application in the time domain or the frequency domain is of no consequence and exactly the same results should be obtained in both cases if the filter response in the frequency domain is the same.

Equally unimportant is the choice of the actual generic filter: users are faced with a wide range of filters to choose from, including Ormsby, elliptical, Butterworth, Chebychev and Bessel. The correct application of the chosen filter is much more important than the choice of a particular filter, so no space is expended here on the minor differences between the various options. An important issue is that the user can get access to a filter in a way that facilitates operation with complete control over the various parameters rather than employing the filter as a 'black box'.

The purpose of a low-cut filter is to remove that part of the signal that is judged to be heavily contaminated by long-period noise. The key issue is selecting the period beyond which the signal-to-noise ratio is unacceptably low (Section 5.3). Applying a filter that abruptly cuts out all motion at periods above the desired cut-off can lead to severe distortion in the waveform, and therefore a transition—sometimes referred to as a ramp or a rolloff—is needed between the pass-band, where the filter function equals unity, and the period beyond which the filter function is equal to zero. Fig. 13 shows the form of a low-cut Butterworth filter, defined by a filter frequency and an order: the higher the order of the filter, the more rapid the roll-off (but with increased filter-response oscillations for the higher order filters).

Although the choice of filter type is less important, the way in which the filter is applied to the accelerogram has been shown to be very important. The fundamental choice is between causal and acausal filters, the distinguishing feature of the latter being that they do not produce any phase distortion in the signal, whereas causal filters do result in phase shifts in the record. The zero phase shift is achieved in the time domain by passing the transform of the filter along the record from start to finish and then reversing the order

![](images/1d7df08312e6995e8a20b29b8d05ab8493e9c6095de0d6275ab62b9cf5923b24.jpg)  
Fig. 14. The total length of the time-domain zero pad recommended by Converse and Brady [17] to allow for the filter response in 2-pass (acausal),  $n$ th-order Butterworth filters (these pads are needed regardless of whether the filtering is done in the time- or frequency-domain). Pre- or post-event data count as part of the required pad length. Shown are the pad lengths for three values of the filter corner frequency, as a function of filter order.

![](images/e15160601a5217a271f48caf17f30678d697fe97aba6b68b176349d1cd1442be.jpg)  
Fig. 15. Accelerations, velocities, and displacements from the  $228^{\circ}$  component of the analog recording at Rinaldi during the 1994 Northridge earthquake for causal (top) and acausal (bottom) filtering. The time scales are different for the acceleration, velocity, and displacement time series to better display certain features.

and passing the filter from the end of the record to the beginning.

The reason that the filters are described as acausal is that to achieve the zero phase shift they need to start to act prior to the beginning of the record, which can be accomplished by adding lines of data points of zero amplitude, known as pads, before the start of the record and after the end of the record. The length of the pads depends on the filter frequency and the filter order (Fig. 14). The required length of the filter pads will often exceed the usual lengths of pre- and post-event memory on digital recordings, hence it is not sufficient to rely on the memory to act as the pads.

The application of causal and acausal filters, even with very similar filter parameters (the transfer functions will not be identical if time-domain filtering is used, since the causal filter will have a value of  $1 / \sqrt{2}$  at the filter corner frequency,  $f_{\mathrm{c}}$ , whereas the acausal filter will have a value of 0.5, regardless of the filter order), have been shown to produce very different results in terms of the integrated displacements (Fig. 15) and the elastic spectral response ordinates (Fig. 16). The surprising feature of Fig. 16 is the influence that the low-cut period can have on the short-period spectral ordinates when causal filters are used. The influence of causal and acausal filters on both elastic and inelastic response spectra has been investigated by Boore and Akkar [30], who found that the both elastic response spectra and inelastic response spectra computed from causally-filtered accelerations can be sensitive to the choice of filter corner periods even for oscillator periods much shorter than the filter corner periods.

When adding zero pads to accelerograms prior to filtering, a potential undesired consequence is to create abrupt jumps where the pads abut the record, which can introduce ringing in the filtered record. There are two different ways to avoid this, one being to use tapers such as a

half-cosine function for the transition from the motion to the zero pad. A simpler procedure is to start the pad from the first zero crossing within the record, provided that this does not result in the loss of a significant portion of record, as can happen if the beginning or end of the acceleration time series is completely above or below zero. When acausal filters are applied, the pads are a tool of convenience but their retention as part of the processed record can be important, as explained in Section 5.2.

![](images/ec3c231bae4a5b238c88cc463d59be7421c07e3214ccb089e805882c57300f12.jpg)  
Fig. 16. Ratio of  $5\%$  -damped pseudo absolute acceleration spectra from the  $228^{\circ}$  component of the analog recording at Rinaldi during the 1994 Northridge earthquake for causal (top) and acausal (bottom) filtering, using the results for a filter corner of  $100\mathrm{s}$  as reference.

# 5.2. Compatible measures of ground motion

Processed accelerograms are generally distributed as files of equally-spaced samples of acceleration, velocity and displacement, and these are often accompanied by the response spectra for various damping levels. Users are often troubled by the fact that if they integrate the acceleration time-history the velocities and displacements that they obtain do not match those provided by data distributors. In addition to this, the response spectra calculated from the acceleration time-histories will often not match the response spectra provided by the distributor, at least, for example, in so much as the long-period displacements may not converge to the peak ground displacement. In such cases, the data can be described as incompatible [15,31,32]; compatible data mean that the velocity and displacement time-histories and the response spectra obtained from the accelerations will match those provided.

There are two different causes for incompatible data. One is the practice of filtering the accelerations and then integrating these to obtain velocities, to which another filter is applied in order to reduce noise that is still present in the record. The process is then repeated on the displacements [5,33]. The problems arise because the effects of the filters

applied to the velocity and/or displacement are not carried back to the acceleration, hence the results from integration of the acceleration no longer match the velocity and the displacement that have been filtered. Careful selection of the filter parameters—and if necessary combining the filter with a reference baseline adjustment (Section 5.6)—and appropriate handling of zero pads should make such iterative filtering unnecessary and certainly the practice of applying multiple filters is one that is to be discouraged.

Another cause for data incompatibility is the removal of the pads that are added for the application of the filter. This is an issue that creates some controversy because some argue that the pads are artificial and therefore do not constitute part of the data and hence should be removed. The consequence of their removal, however, is to undermine the effect of the filter and this can result in offsets and trends in the baselines of the velocity and displacements obtained by integration (Fig. 17). The removal of the pads also has an influence on the long-period response spectral ordinates (Fig. 18). For this reason, it is recommended that when acausal filters are used, sufficient lengths of zero pads should be added to the records and these pads should not be stripped out from the filtered data [17].

![](images/69b0152d68a546db661ad7fe50503bc401b3c84b05272afa4e6b9be7405bef2f.jpg)  
Fig. 17. Accelerations, velocities, and displacements derived from the EW component accelerations recorded at El Centro station 9 during the 1940 Imperial Valley earthquake, illustrating the incompatibility of the processed data that does not include the padded portions of the processed data. The left panel shows results from padded and filtered data. In the right panel the padded portions have been removed from the processed acceleration time series (this corresponds to what several data agencies provide to the public) and the velocity and displacement have been obtained by integration of this pad-stripped data, assuming zero initial conditions. This is a particularly egregious example, but many records share the general features shown here. The unprocessed data are from Seekins et al. [34].

![](images/278e49037ac1f80bedc8dd5f02d66f7e7192bde6badea5301f3036eef0f441ab.jpg)  
Fig. 18. Absolute acceleration response (SA) and spectral displacement (SD) computed for the El Centro station 9 recording of the 1940 Imperial Valley earthquake, from the filtered acceleration before and after removal of the zero padded portion. Note that SA and SD have been plotted using linear and logarithmic axes, respectively.

# 5.3. Selection of long-period cut-offs

As noted previously, the most important issue in processing strong-motion accelerograms is the choice of the long-period cut-off, or rather the longest response period for which the data are judged to be reliable in terms of signal-to-noise ratio. A number of broad criteria can be employed by the analyst to infer the period beyond which it is desirable to apply the filter cut-off, including:

- Comparison of the FAS of the record with that of a model of the noise, obtained from the pre-event memory for digital records, the fixed trace from analog records or from studies of the instrument and digitizing apparatus. A point of clarification is appropriate here regarding signal-to-noise ratios: the comparison of the record FAS with the FAS of the noise indicates the ratio of signal-plus-noise to noise, hence if the desired target is a signal-to-noise ratio of 2, the ratio of the record FAS to that of the noise model should be 3.

- Judgment of where the long-period portion of the record FAS deviates from the tendency to decay in proportion to the reciprocal of the frequency squared. Whether one assumes the single corner-frequency model of Brune [35,36] or the more complex models with two corner frequencies [37-40], seismological theory dictates that at low frequencies, the FAS of acceleration decays according to  $f^2$  (by virtue of the fact that the long-period displacement time series radiated from earthquakes will be pulse-like, ignoring residual displacements, and the FAS of the displacement pulse will therefore be finite at zero frequency).

- Visual inspection of the velocity and displacement time-histories obtained by double integration of the filtered

acceleration, and judgment of whether or not these quantities appear to be unphysical. An adjective often used to justify the filter parameters on the appearance of the resulting velocities and displacement is 'reasonable', but this is poorly defined and what is reasonable to one observer may not be so for another.

![](images/21754c0223fac989e43dd9dcaa98ef16c4b03f1b7e2ddb552bf2a83b6773ccb5.jpg)  
Fig. 19. Fourier acceleration spectrum of a digitized version of an analog recording for three values of  $f_{c}$ . Also shown is the theoretical low-frequency slope for a single-corner source model, and representative noise curves from Lee and Trifunac [33], from which a signal-to-noise ratio of 3 would suggest that the filter corner should be near  $0.06\mathrm{Hz}$ .

The optimum approach is to make use of all three criteria simultaneously. The first two options are illustrated in Fig. 19 for the selection of filter parameters for a component of the Anderson Dam (analog) recording of the 1989 Loma Prieta earthquake. The FAS of the record is compared with the model for the digitization noise proposed by Lee and Trifunac [33]. Also shown is the gradient of the  $f^2$  line, superimposed as a best fit (by eye) on the section of the FAS where the decay at low frequencies commences. Also shown in the graph are the FAS of the record after applying filters with three different low-frequency cut-offs. The reader should note that these decay more rapidly than indicated by the  $f^2$  model, which is the expected result of effectively trying to remove all of the record—both signal and noise—at periods greater than the cut-off. Designing a filter with a gradual roll-off that will produce an FAS that approximates to the  $f^2$  model is not advisable since the agreement with the theoretical seismological model would not mean that the real earthquake signal has been recovered, but only that an unknown mixture of signal and noise has been manipulated to produce the appearance of a genuine seismic motion.

Fig. 20 shows the acceleration, velocity and displacement time-series obtained by applying the three low-cut filters in Fig. 19. The largest discernable differences are in the displacement traces, with the peak amplitude varying by a factor of about three. However, none of the three displacement time-series could be judged to be clearly unphysical,

although there do appear to be some unusual long-period fluctuations in the record filtered at  $20\mathrm{~s}$ . This suggests that whilst the appearance of the velocities and displacements may serve to reject some filter options, it is unlikely to indicate an unambiguous choice of optimal filter parameters.

The processing of strong-motion accelerograms is usually performed component-by-component. In Section 5.5, the issue of whether the individual components of a triaxial recording should be treated individually is addressed, but there is also the issue of whether records from different stations should be processed without regard to the processing of data from nearby stations that have recorded the same earthquake. Fig. 21 shows the location of strong-motion accelerographs that recorded the 2002 Denali fault earthquake in Anchorage, all at distances from the fault rupture of more than  $290\mathrm{km}$ . The map shows that the stations were located on sites that fall into three different classes according to the NEHRP scheme.

Fig. 22 shows displacement traces of all three components from two of the stations, located on different site classes. Although the two records display different proportions of high-frequency radiation by virtue of the different stiffness of the near-surface geology at the two locations, there is a remarkable degree of coherence in the long-period part of the motion. This coherence at long-periods is frequently observed and where there are large numbers of records from a given earthquake, the coherence can be used as an additional criterion to assess whether

![](images/73e78fefbffec1e4538e25ceb482d6e59925e82906fd0b779ef962a5b99b61d2.jpg)  
Fig. 20. Acceleration, velocity, and displacement using three values of  $f_{c}$ . The displacement from the unfiltered acceleration is shown in gray.

![](images/ae20b5d59a01b74371c21b2061ec033d4152626cc25733be5e994d81d3c8636a.jpg)  
Fig. 21. Location of stations and NEHRP site classes (site classes and base map from Fig. 12 in Ref. [41]). The C/D class is intermediate between NEHRP classes C and D, and is defined by Martirosyan et al. [41] by the average  $30\mathrm{m}$  shear wave velocity being between 320 and  $410~\mathrm{m / s}$ .

appropriate filter parameters have been applied [18,42]. An example of such spatial coherence is given in Fig. 23. An exception to this will be the case of near-source recordings affected by rupture directivity effects [43], unless the stations are very close together.

A final point concerns an additional criterion, which although not a basis for selecting the filter parameters may

serve to judge whether the chosen low-cut filter is appropriate or indeed acceptable. The theoretical FAS of earthquake ground motion, if following a single corner-frequency model, begins to decay in amplitude at frequencies lower than the corner frequency  $f_{0}$ . The corner frequency is essentially proportional to the inverse of the rupture duration which, since rupture propagation velocities are usually between 2 and  $3\mathrm{km / s}$ , is related to the length of the fault rupture and hence the magnitude (or moment) of the earthquake. If the signal-to-noise ratio demands that a high filter cut-off is set at a frequency higher than  $f_{0}$ , it means that an integral part of the signal is being removed and the filtered data is of little physical significance and hence should be used with caution.

To derive predictive equations for peak ground-motion parameters in Europe, Tromans and Bommer [44] used a databank of mainly analog recordings, selecting the filter parameters mainly on the basis of inspection of the velocity and displacement time-histories obtained from the filtered accelerations. Subsequent inspection of the filter frequencies revealed that many of these were above the theoretical corner frequencies, especially for small-to-moderate magnitude earthquakes, which casts doubt on the reliability of the results for peak ground velocity (PGV) and peak ground displacement (PGD). The close agreement of these predictive equations with those of Margaris et al. [45] suggests that the latter were also based on data for which excessively severe filters may have been applied. This is not to say, however, that either study is in itself erroneous, but rather that analog data may be of limited usefulness other

![](images/2ed3cb0cc3c8fe3f4eb4272e3da87fe3e694a40f21052ead3e90f498e48f1f4f.jpg)  
Fig. 22. Displacements at stations K2-16 and K2-20 (see Fig. 21), showing the strong coherence at low frequencies. Station K2-20 is on lower velocity materials and has more high frequency motion than does station K2-16. Gray curves have been low-cut filtered at  $0.02\mathrm{Hz}$ ; black curves have been low-cut filtered at  $0.02\mathrm{Hz}$  and high-cut filtered at  $0.08\mathrm{Hz}$ .

![](images/2a950a6230aa213938b404cee7bc45787c4713563d2c641b09031f5b508e3d0c.jpg)  
Fig. 23. Comparison of the processed velocity and displacement traces from the NS components of two stations located about  $1.6\mathrm{km}$  apart and about  $160\mathrm{km}$  west of the  $M_{\mathrm{w}}$  7.2 Hector Mine earthquake in 1999. Note the remarkable similarity between the signals at these two stations, particularly at long periods. Comparisons such as this are used to confirm that proper filter corners were selected to process the records.

![](images/31e7f2a6570746f6f8cf85b53d701696539fe60b2b1b6dd5c4d453c194f8cb5d.jpg)

than to derive predictions of spectral acceleration ordinates at periods shorter than about 2 or  $3\mathrm{s}$ .

# 5.4. Usable range of response periods

The amplitude of long-period response spectral ordinates are highly sensitive to the parameters of low-cut filters, and this is most clearly visible when looking at the spectra of relative displacement. Fig. 24 shows that care must be taken in deciding the range of periods for which the spectral ordinates can be reliably used, which depends on both the filter frequency and the order of the filter. For a low-order filter applied at  $20\mathrm{~s}$ , the spectral ordinates should probably not be used much beyond  $10\mathrm{~s}$ . The studies by Abrahamson and Silva [46] and Spudich et al. [47] to derive predictive equations for response spectral ordinates only used each record for periods up to 0.7 times the cut-off period. Bommer and Elnashai [48], in deriving predictions for displacement spectral ordinates, used each record up to  $0.1\mathrm{~s}$  less than its cut-off period, which will have inevitably resulted in underestimation of the spectral displacements at longer periods. Berge-Thierry et al. [49] used records from the European Strong-Motion Databank [50], filtered at  $4\mathrm{~s}$ , to derive equations to predict pseudo-acceleration spectral ordinates for periods up to  $10\mathrm{~s}$  (Fig. 25).

The spectral ordinates predicted by the equations of Berge-Thierry et al. [49] at periods higher than 3.0 s have no physical meaning and the apparent peak in the spectrum close to 4 s is more likely to be a result of the filtering of the records than a genuine feature of the ground motion. This also casts significant doubts on the Eurocode 8 [51] spectrum, with which the Berge-Thierry et al. [49] predictions are compared in Fig. 25. For most analog recordings, it is unlikely that reliable spectral ordinates can be obtained for periods much beyond 3 or 4 s, hence the derivation of reliable long-period displacement spectra will need to be based on seismological

modeling and the use of high-quality digital recordings. The NEHRP 2003 guidelines predict long-period spectral ordinates that have been restrained by either seismological criteria or digital accelerograms; digital recordings from the Denali earthquake have been shown to match very well with the 2003 NEHRP spectrum [52]. If it is assumed that the NEHRP corner periods are more applicable than the current

![](images/0cd26074f3d5b7415b9726435f3e29c2cdca4bbf4c7c6bdf2a721349baa27911.jpg)  
Fig. 24. Response spectra with and without acausal, time-domain (2-pass) filtering. The unfiltered spectrum is shown in two versions: as is (thick line) and multiplied by 0.94 to better compare the filtered response with expectations based on the filter frequency-response analysis (thin line). The filtering is for a series of filter orders and a single value of corner frequency. The dashed vertical line indicates the filter corner. The solid vertical lines denote periods for which the filter response is down by about  $-1/2$  db (a factor of 0.94) for the various filters, as indicated by the values of filter order  $n$ .

![](images/11b85a6497d2faec9ae17a4d97a7643a8705a51becb7dad20382b02a13029eef.jpg)  
Fig. 25. Displacement response spectra for rock sites due to a magnitude 7 earthquake at a hypocentral distance of  $15\mathrm{km}$  obtained from the equations of Berge-Thierry et al. [49] and from Eurocode [51]. The dashed line shows the form of the EC8 spectrum if the same corner frequency as specified in the 2003 NEHRP guidelines for this magnitude were adopted. All three spectra have been anchored to the same ordinate at  $1.0\mathrm{s}$ .

Eurocode 8 value of just  $2\mathrm{s}$ , the implications are that long-period spectral displacements in Eurocode 8 are severely underestimated (Fig. 25).

# 5.5. Components of multi-axial recordings

Most accelerograms, especially analog recordings, include three orthogonal components of motion, one in the

vertical direction. An issue to be considered in record processing is whether the same filter parameters should be used for all three components or whether optimal processing should be used to obtain the maximum information possible from each of the three components. If the same processing is applied to all three components, the filter cut-off will generally be controlled by the vertical component since this will usually have a lower signal-to-noise ratio than the horizontal components, particularly in the long-period range. Therefore, unless there is a compelling reason for the vertical and horizontal components to be processed with the same filter, this practice is not recommended. Similar arguments hold for strongly polarized horizontal components of motion, as may be encountered in near-source recordings, since the stronger component could be subjected to an unnecessarily severe filter because of the lower signal-to-noise ratio of the fault parallel component.

There are applications for which it is important that the components of accelerograms, especially the horizontal components, be processed in a uniform manner. These applications include resolution of the components, for example into fault normal and fault parallel components, or to find the absolute maximum horizontal amplitude. Another example is when there are accelerograms obtained at ground level and from upper stories of buildings or from the superstructure of bridges, which will be used to compare the seismic response of the structure to predictions from modeling. In all these applications, it is important in particular to retain the phase characteristics of the motion and not to introduce any offsets in the time scale of one

![](images/c364c290287f25395969fb22ac17a0dc74a9064e180d4f6c5b431b832f9342fd.jpg)  
Fig. 26. Velocities and displacements for a number of methods of baseline adjustment and filtering. The second trace from the top shows the result of low-cut filtering with no baseline adjustment (the corner frequency of  $0.07\mathrm{Hz}$  was chosen subjectively). The bottom trace corresponds to the multisegment fits, with low-cut filtering. The record is the EW component recording at Olive Dell Ranch of the  $M_{\mathrm{L}}$  4.4 February 21 2000 Loma Linda, California, earthquake. Note that in each plot a different scale is used.

![](images/d076d16585995f4275b1780bef4884750b623b6aae7a2acaab04bcd4e5936e77.jpg)

component with respect to another. For such applications it is vital that acausal filters be employed (unless baseline corrections are sufficient to remove long-period noise), using the same pad lengths for both components, which will therefore be determined by the filter parameters that result in the longer pads.

# 5.6. Combining filters and baselines

An option that is always available is to use both low-cut filters and baselines together as tools to remove long-period noise from the accelerograms. Fig. 26 compares the velocity and displacement time-histories of a single component of a digital accelerometer processed using only a baseline, only a filter and a combination of the two. The appearance of the traces obtained by the application of a filter and a baseline is certainly the most physical of the three cases, particular in terms of the displacements. The low-period filter corner was set at  $14.3\mathrm{s}$  hence it is unlikely that the oscillations at about  $10\mathrm{s}$  period in the latter part are a filter transient although radiation in this period range would have been weak from this small magnitude  $(M_{\mathrm{L}}4.4)$  event. The amplitude of the motion, however, is very small, with a maximum displacement of the order of  $0.1\mathrm{mm}$ . Note that the displacements obtained by applying the low-cut filter alone have amplitudes more than an order of magnitude greater; in this case, the highest displacement, near the beginning of the record, is coming from the filter transient (in the pads) rather than the motion itself. The displacement response spectra obtained from the different processing approaches are shown in Fig. 27.

![](images/727131d977554a3de2ce5e6a124bba4f4bac91815babdbd1b6e2299e911a8e13.jpg)  
Fig. 27. The response spectra computed from the processed acceleration traces used to derive the velocities and displacements shown in the previous figure. For this record, baseline correction alone removes much of the long-period noise (compare the short-dashed line and light solid line).

# 6. Discussion and conclusions

This paper was motivated by a workshop on strong-motion record processing organized by COSMOS in May 2004; the guidelines from the workshop [53,54] are summarized in the Annex. The paper has aimed to illustrate the implementation and consequences of these guidelines and also to provide a concise overview of the key issues, in a single publication, specifically for engineers.

Three important conclusions of a general nature can be drawn. Firstly, strong-motion records are always affected by noise to some degree and therefore processing procedures need to be applied, with the consequence that some portion of the signal (in the frequency domain) must be sacrificed. Secondly, the key issue is determining what range of frequencies can be reliably used considering both signal-to-noise ratios and the adjustments applied to the record. Thirdly, there is no panacea for removing noise in strong-motion recordings because there is a wide range of noise sources and a lack of accurate noise models; the procedures adopted will depend on the type of instrument and the nature of the ground motion recorded, as well as the engineering application for which the processed records will be used.

In general, except for recordings obtained with the earliest strong-motion accelerographs and for recordings on very hard rock sites, corrections for instrument transducers are not required. The application of an instrument correction can have the effect of amplifying high-frequency noise. In most cases it will actually be desirable to apply a high-cut filter to the record in order to remove the high-frequency noise whether or not an instrument correction has been applied; the high-frequency cut-off should take account of the Nyquist frequency as determined by the time interval of the digital record.

The most important processing for all records is the application of low-cut filters to remove the low-frequency parts of the record contaminated by long-period noise. The choice of the type of filter to be used is relatively less important, but it has been shown that unless there are compelling reasons to do otherwise, the filters should be applied acausally. To apply an acausal filter, it is important to provide adequate zero pads and in order to produce compatible time-series and response spectra, these pads must be retained in the processed acceleration signal.

The most important aspect of applying a low-cut filter is selecting the long-period cut-off, for which a model of the noise is ideally required. The choice is never unambiguous and depends on what is considered to be an acceptable signal-to-noise ratio. From an engineering perspective the most important point is that once the filter frequency is selected, this automatically defines the range of periods over which the data is usable; for analog strong-motion accelerograms, it will generally not be possible to use the spectral ordinates for periods much beyond 3 or 4 s except

for the very strongest records, if these have been very carefully digitized.

Baseline fitting techniques can be used to adjust for reference baseline shifts in both digitized analog records and digital recordings. Baseline adjustments can also be used to remove long-period noise, although this effectively means applying a low-cut filter of unknown frequency. In some cases, baseline adjustments can be used in conjunction with filters to provide optimum record processing. One advantage of baseline fitting techniques over filters is that the former can enable residual displacements to be recovered, although to date there are very few cases where displacements obtained in this way have been validated by independent observations and the baseline fitting procedures tend to be highly sensitive to the parameters selected by the user.

Two important conclusions can also be drawn with regards to the policies of agencies distributing strong-motion records to end users. The first is that if records are filtered or otherwise processed prior to distribution, the meta-data describing the processing in detail should be distributed together with the accelerometer (for example, in the file header) or otherwise made easily accessible to the users. A critical piece of information that must be conveyed with processed strong-motion data is the range of periods over which the data can be used. The second conclusion is that because of the implications of different processing procedures for different engineering applications, it would be of great benefit for agencies to also distribute the unprocessed digitized data (after the removal of non-standard errors such as those described in Section 2.4). This would allow users to apply their own processing procedures to the records in those cases where the adjustments made by the distributing agency are for some reason not the most suitable for the application in hand.

# Acknowledgements

The authors firstly would like to thank the organizers of the COSMOS workshop on strong-motion record processing held in California in May 2004, which inspired the authors to write this paper. We acknowledge all the contribution of all the participants at the workshop through their presentations and the stimulating discussions that these generated. Particular mention is due to Chris Stephens for many discussions and suggestions regarding record processing. Our thanks to Sinan Akkar for his careful review of an earlier draft of the paper, which helped to eliminate a number of errors. We are particularly grateful to John Douglas and Chris Stephens for very thorough reviews of the manuscript that led to important improvements, and to Guo-quan Wang for drawing our attention to 'jerk' as a measure of ground motion. Finally, we would also like to acknowledge our debt to St Cecilia, patron saint of

musicians, for her restraint: had she bestowed on either of us talent in the same proportion as enthusiasm, this paper—and many others—would never have been written.

# Appendix A. Summary guidelines and recommendations for strong-motion records processing from COSMOS record-processing workshop [53]

Uniform standards for processing are not achievable at this time because of a variety of issues. However, processing agencies are encouraged to use these recommended processing guidelines. The processing procedures that are used should be clearly documented so that the results can be reproduced. The user should be able to determine from the data and its metadata what procedures have been applied.

In general, the expression 'corrected data' should be avoided, in favor of 'processed data'. In these guidelines, Vol. 1 means the unprocessed record, with no filtering or instrument correction procedures applied, though deglitching and other basic signal conditioning steps may have been performed on the raw data. Also, a 'record' here means all of the channels recording the response of the station or structure.

Processing agencies are encouraged to provide a readily accessible, clear, and thorough description of the processing procedure used by their agency.

1. Compatible vs. Incompatible processed data products. Insofar as possible, data products released should be 'compatible'—that is, released acceleration should be able to be used, by a general user, to calculate velocity, displacement and spectra which match those released with the acceleration. Cases where this is not done should be clearly noted by the releasing agency, through comments and/or reference to a tutorial document.  
2. Filtering by record vs. filtering by channel. Currently, records are released by agencies like the USGS and CGS with all channels filtered with the same filter corner. In many cases, it is also beneficial for the records to be released with, for example, all horizontals filtered the same, or every channel filtered separately. If included, the set of individually filtered channels should be clearly indicated as an alternate set. Clear documentation for the user is important, so that the difference is understood. An alternate way to address this need may be the release of the unprocessed data, so that a knowledgeable user can process the records as desired.  
3. Release of unprocessed data. The ability of investigators to work with unprocessed data is critical for research and progress in understanding noise characteristics, data offsets, and other issues. COSMOS member agencies are encouraged to release unprocessed (Vol. 1) data for research, and upon special request, to provide raw data as well. Organizations in a position to process data for open release are requested not to process, for release, data already released by the source network because of the potential confusion

multiple releases of processed records would cause. It is incumbent upon anyone releasing reprocessed data to be very clear what the differences are relative to the original release.

4. Usable data bandwidth. The usable data bandwidth should be documented and distributed with processed data, in a way clear to the data user. Recommendations against use of the data outside of this bandwidth should be included with the data file, and in an expanded form in documents on the agency's or other website. Response spectral values should only be provided within the Usable Data Bandwidth defined by the processing group. This limitation should be documented to the users.

5. Acausal filters. In general, acausal filters should be used unless there are special factors involved. This has been found to be particularly important if the data will be used to generate inelastic response spectra. Any usage of causal filters should be clearly documented in the information and comments accompanying the data. If causal filters are used (e.g. in real-time applications), it is important that the same filter corner be used for all components.

6. End effects. In routine processing, one way late-triggered records may be treated is by tapering of the records before processing. A raised cosine applied to the first and last few (e.g. 5) percent of the record length is a reasonable taper. Late triggered records and records with permanent offset should only be tapered with care, and for these cases a more complex (or no) tapering may be appropriate. Any tapering done should be documented. In addition to tapering, another approach is to trim the record at the location of the first zero-crossing in the record.

Processing of late-triggered records (i.e. records with little or no recorded data before the high amplitude motion) is quite uncertain, and more than normally dependent on details of the procedures used in processing. In general it is recommended that late-triggered records not be used if otherwise equivalent records are available.

7. Time domain vs. frequency domain. In general, excluding base line corrections, careful processing done with time domain and frequency domain procedures yield comparable results.

8. Metadata. Metadata (i.e. information about the data) should be provided with the data. To prevent confusion by users, the original metadata should be preserved in the data file, and indicated as the original metadata, by other agencies reprocessing or redistributing the data. Modifications or additions to the metadata should also be clearly indicated in the metadata. A minimum set of parameters should be provided in the metadata.

9. High frequencies. High frequencies can be important at hard rock sites, and in areas of low attenuation. Data should be provided out to as high a frequency as allowed by the signal and noise. A sampling rate as high as feasible (e.g. 200 sps or higher) is important for good definition of the strong acceleration pulses. The anti-aliasing filter of the recorder should be consistent with the sample rate.

10. Instrument correction. Complete information about the instrument response and any instrument correction performed should be documented with the data.

11. Sensor offsets. Sensor offsets can be a significant issue with modern data. The presence of offsets should be checked as a part of determining whether routine processing can be applied (e.g. by removing a suitable reference level(s) and checking the velocity for trends, or equivalently checking for different DC acceleration levels at the start and end of a record). Offsets can be estimated by several techniques; the most successful at this time requires a case-by-case approach involving inspection of intermediate time series and/or spectra.

12. Selecting long period filter period. In the absence of offsets (or after correction for them) the long period filter corner selection should incorporate analysis of signal and noise. Using a ratio of recorded signal-to-noise of not less than 2 is recommended. This selected period should be reviewed in the time domain to verify that clearly unphysical velocity and displacement time series are not produced (considering similarity of displacements obtained for nearby stations is a recommended technique, when possible). Peak displacement is strongly dependent on the long period filter corner. True permanent displacement may, in general, not be obtainable from triaxial strong motion records alone.

Due to uncertainty in obtaining permanent displacement from accelerometers, networks are encouraged to include direct measurement of displacement (e.g. selective collocation of differential GPS instruments) in strong motion networks.

13. Processed data format. To increase convenience for data users and simplify data exchange with other networks, processing agencies are encouraged to release their processed data in the COSMOS format (www.cosmos-eq.org), or alternatively, to provide a conversion module at their website to convert files from their format to the COSMOS format.

# References

[1] Trifunac MD, Udwadia FE, Brady AG. Analysis of errors in digital strong-motion accelerograms. Bull Seismol Soc Am 1973;63:157-87.  
[2] Hudson DE. Reading and interpreting strong motion accelerograms. Earthquake engineering research institute monograph, Berkeley, California. vol. 1 1979. p. 112.  
[3] Trifunac MD, Todorovska MI. Evolution of accelerographs, data processing, strong motion arrays and amplitude and spatial resolution in recording strong earthquake motion. Soil Dyn Earthquake Eng 2001;21:537-55.  
[4] Shakal AF, Ragsdale JT. Acceleration, velocity and displacement noise analysis for the CSMIP acceleration digitization system. Proceedings of the Eighth World Conference on Earthquake Engineering, San Francisco 1984;vol. II:111-8.  
[5] Lee VW, Trifunac MD. Current developments in data processing of strong motion accelerograms. Report 84-101. Los Angeles:

Department of Civil Engineering, University of Southern California; 1984 [Report 84-01].  
[6] Skarlatoudis AA, Papazachos CB, Margaris BN. Determination of noise spectra from strong motion data recorded in Greece. J Seismol 2003;7:533-40.  
[7] Douglas J. What is a poor quality strong-motion record? Bull Earthquake Eng 2003;1:141-56.  
[8] Iwan WD, Moser MA, Peng C-Y. Some observations on strong-motion earthquake measurement using a digital accelerometer. Bull Seismol Soc Am 1985;75:1225-46.  
[9] Shakal AF, Petersen CD. Acceleration offsets in some FBA's during earthquake shaking (abst.). Seismol Res Lett 2001;72:233.  
[10] Wang G-Q, Boore DM, Igel H, Zhou X-Y. Some observations on colocated and closely-spaced strong ground motion records of the 1999, Chi-Chi, Taiwan earthquake. Bull Seismol Soc Am 2003;93: 674-93.  
[11] Boore DM. Analog-to-digital conversion as a source of drifts in displacements derived from digital recordings of ground acceleration. Bull Seismol Soc Am 2003;93:2017-24.  
[12] Trifunac MD. A note on correction of strong-motion accelerograms for instrument response. Bull Seismol Soc Am 1972;62: 401-9.  
[13] Trifunac MD, Lee VW, Todorovska MI. Common problems in automatic digitization of strong motion accelerograms. Soil Dyn Earthquake Eng 1999;18:519-30.  
[14] BSSC. NEHRP recommended provisions for seismic regulations for new buildings and other structures, 2003 Edition. Part 1—Provisions, Part 2 Commentary; prepared by the Building Seismic Safety Council for the Federal Emergency Management Agency (Report No. FEMA 450): Washington, DC; 2004 [available from http://www.bssconline.org/].  
[15] Shyam Sunder S, Connor JJ. A new procedure for processing strong-motion earthquake signals. Bull Seismol Soc Am 1982;72: 643-61.  
[16] Joyner WB, Boore DM. Measurement, characterization, and prediction of strong ground motion. Earthquake Engineering and Soil Dynamics II. Proceedings American Society Civil Engineering Geotechnical Engineering Division Specialty Conference, Park City, Utah 1988 p. 43-102.  
[17] Converse AM, Brady AG. BAP—basic strong-motion accelerogram processing software; Version 1.0. United States Geological Survey Open-File Report 1992 p. 174; 92-296A.  
[18] Boore DM, Stephens CD, Joyner WB. Comments on baseline correction of digital strong-motion data: Examples from the 1999 Hector Mine, California, earthquake. Bull Seismol Soc Am 2002;92: 1543-60.  
[19] Graizer VM. Determination of the true ground displacement by using strong motion records. Izvestiya, Phys Solid Earth 1979;15: 875-85.  
[20] Boore DM. Effect of baseline corrections on displacements and response spectra for several recordings of the 1999 Chi-Chi, Taiwan, earthquake. Bull Seismol Soc Am 2001;91:1199-211.  
[21] Zhu L. Recovering permanent displacements from seismic records of the June 9, 1994 Bolivia deep earthquake. Geophys Res Lett 2003;30: 1740.  
[22] Honegger DG, Nyman DJ, Johnson ER, Cluff LS, Sorensen P. Trans-Alaska pipeline system performance in the 2002 Denali Fault, Alaska, earthquake. Earthquake Spectra 2004;20(3):707-38.  
[23] Priestley MJN, Calvi GM. Strategies for repair and seismic upgrading of Bolu Viaduct 1, Turkey. J Earthquake Eng 2002;6(1): 157-84.  
[24] Park SW, Ghasemi H, Shen J, Somerville PG, Yen WP, Yashinksy M. Simulation of the seismic performance of the Bolu viaduct subjected to near-fault ground motions. Earthquake Eng Struct Dyn 2004; 33(13):1249-70.

[25] Clinton JF. Modern digital seismology—instrumentation, and small amplitude studies in the engineering world. PhD Thesis. California Institute of Technology: Pasadena, California; 2004.  
[26] Ji C, Larson KM, Tan Y, Hudnut KW, Choi K. Slip history of the 2003 San Simeon earthquake constrained by combining 1-Hz GPS, strong motion and teleseismic data. Geophys Res Lett 2004;31:17608.  
[27] Graizer VM. On inertial seismometry. Izvestiya, Phys Solid Earth 1989;25:26-9.  
[28] Trifunac MD, Todorovska MI. A note on the useable dynamic range of accelerographs recording translation. Soil Dyn Earthquake Eng 2001;21:275-86.  
[29] Trifunac MD. Zero baseline correction of strong-motion accelerograms. Bull Seismol Soc Am 1971;61:1201-11.  
[30] Boore DM, Akkar S. Effect of causal and acausal filters on elastic and inelastic response spectra. Earthquake Eng Struct Dyn 2003;32: 1729-48.  
[31] Malhotra PK. Response spectrum of incompatible acceleration, velocity, and displacement time histories. Earthquake Eng Struct Dyn 2001;30:279-86.  
[32] Boore DM. On pads and filters: processing strong-motion data. Bull Seismol Soc Am 2005;95 [in press].  
[33] Lee VW, Trifunac MD. Automatic digitization and processing of accelerograms using PC. Los Angeles: Department of Civil Engineering, University of Southern California; 1990 [Report 90-03].  
[34] Seekins LC, Brady AG, Carpenter C, Brown N. Digitized strong-motion accelerograms of North and Central American earthquakes 1933-1986. US Geol Surv Digital Data Ser 1992;DDS-7.  
[35] Brune JN. Tectonic stress and the spectra of seismic shear waves from earthquakes. J Geophys Res 1970;75(26):4997-5002.  
[36] Brune JN. Correction. J Geophys Res 1971;76(20):5002.  
[37] Gusev AA. Descriptive statistical model of earthquake source radiation and its application to an estimation of short-period strong motion. Geophys J R Astronom Soc 1983;74:787-808.  
[38] Boore DM, Short-period P- and S-wave radiation from large earthquakes: implications for spectral scaling relations. Bull Seismol Soc Am 1986;76:43-64.  
[39] Atkinson GM. Earthquake source spectra in eastern North America. Bull Seismol Soc Am 1993;83:1778-98.  
[40] Atkinson GM, Boore DM. Ground motion relations for eastern North America. Bull Seismol Soc Am 1995;85:17-30.  
[41] Martirosyan A, Dutta U, Biswas N, Papageorgiou A, Combellick R. Determination of site response in Anchorage, Alaska, on the basis of spectral ratio methods. Earthquake Spectra 2002;18:85-104.  
[42] Hanks TC. Strong ground motion of the San Fernando, California, earthquake: ground displacements. Bull Seismol Soc Am 1975;65: 193-225.  
[43] Somerville PG, Smith NF, Graves RW, Abrahamson NA. Modification of empirical strong ground motion attenuation relations to include the amplitude and duration effects of rupture directivity. Seismol Res Lett 1997;68(1):199-222.  
[44] Tromans IJ, Bommer JJ. The attenuation of strong-motion peaks in Europe. Proceedings of Twelfth European Conference on Earthquake Engineering, London September; paper no. 394 2002.  
[45] Margaris B, Papazachos C, Papaianou Ch, Theodulidis N, Kalogeras I, SKarlatoudis A. Ground motion attenuation relations for shallow earthquakes in Greece. Proceedings of Twelfth European Conference on Earthquake Engineering, London September ; paper no. 385 2002.  
[46] Abrahamson NA, Silva WJ. Empirical response spectral attenuation relations for shallow crustal earthquakes. Seismol Res Lett 1997; 68(1):94-127.  
[47] Spudich P, Joyner WB, Lindh AG, Boore DM, Margaris BM, Fletcher JB. SEA99: a revised ground motion prediction relation for use in extensional tectonic regimes. Bull Seismol Soc Am 1999;89(5): 1156-70.  
[48] Bommer JJ, Elnashai AS. Displacement spectra for seismic design. J Earthquake Eng 1999;3(1):1-32.

[49] Berge-Thierry C, Cotton F, Scotti O, Griot-Pommera D-A, Fukushima Y. New empirical attenuation laws for moderate European earthquakes. J Earthquake Eng 2003;7(2):193-222.  
[50] Ambraseys NN, Smit P, Berardi D, Cotton F, Berge C. Dissemination of European strong-motion data, CD-ROM Collection, European Commission, Directorate-General XII, Environmental and Climate Programme, ENV4-CT97-0397, Brussels, Belgium, 2000.  
[51] CEN. Eurocode 8: Design of structures for earthquake resistance, part 1: general rules. Seismic actions and rules for buildings, stage 49 draft, Comité Européen de Normalisation, Brussels; 2003.

[52] Boore DM. Ground motion in Anchorage, Alaska, from the 2002 Denali fault earthquake: Site response and displacement pulses. Bull Seismol Soc Am 2004;94 [in press].  
[53] Shakal AF, Boore DM, Chiou BS-J, Iwan WD, O'Connell DR, Stepp JC. Proceedings: workshop on strong-motion record processing, COSMOS Publication No. CP-2004/01, Consortium of Organizations for Strong-Motion Observation Systems (COSMOS), Richmond, California; 2004.  
[54] Shakal AF, Boore DM, Chiou BS-J, Iwan W, O'Connell D, Stepp JC. Guidelines and recommendations for strong-motion records processing. COSMOS Newsletter 2004; 11, November: 3-5.